{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6e8fbd",
   "metadata": {},
   "source": [
    "# Import Data From dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee819b5",
   "metadata": {},
   "source": [
    "## Configuring the package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da26853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # Add parent directory to path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f732abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q4E</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q5E</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>religion</th>\n",
       "      <th>married</th>\n",
       "      <th>familysize</th>\n",
       "      <th>major_category</th>\n",
       "      <th>depression_score</th>\n",
       "      <th>anxiety_score</th>\n",
       "      <th>stress_score</th>\n",
       "      <th>das_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3890</td>\n",
       "      <td>4</td>\n",
       "      <td>2122</td>\n",
       "      <td>2</td>\n",
       "      <td>1944</td>\n",
       "      <td>4</td>\n",
       "      <td>2044</td>\n",
       "      <td>4</td>\n",
       "      <td>2153</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8118</td>\n",
       "      <td>1</td>\n",
       "      <td>2890</td>\n",
       "      <td>2</td>\n",
       "      <td>4777</td>\n",
       "      <td>3</td>\n",
       "      <td>3090</td>\n",
       "      <td>4</td>\n",
       "      <td>5078</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5784</td>\n",
       "      <td>1</td>\n",
       "      <td>4373</td>\n",
       "      <td>4</td>\n",
       "      <td>3242</td>\n",
       "      <td>1</td>\n",
       "      <td>6470</td>\n",
       "      <td>4</td>\n",
       "      <td>3927</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5081</td>\n",
       "      <td>3</td>\n",
       "      <td>6837</td>\n",
       "      <td>2</td>\n",
       "      <td>5521</td>\n",
       "      <td>1</td>\n",
       "      <td>4556</td>\n",
       "      <td>3</td>\n",
       "      <td>3269</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3215</td>\n",
       "      <td>2</td>\n",
       "      <td>7731</td>\n",
       "      <td>3</td>\n",
       "      <td>4156</td>\n",
       "      <td>4</td>\n",
       "      <td>2802</td>\n",
       "      <td>4</td>\n",
       "      <td>5628</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A   Q1E  Q2A   Q2E  Q3A   Q3E  Q4A   Q4E  Q5A   Q5E  ...  gender  age  \\\n",
       "0    4  3890    4  2122    2  1944    4  2044    4  2153  ...       2   16   \n",
       "1    4  8118    1  2890    2  4777    3  3090    4  5078  ...       2   16   \n",
       "2    3  5784    1  4373    4  3242    1  6470    4  3927  ...       2   17   \n",
       "3    2  5081    3  6837    2  5521    1  4556    3  3269  ...       2   13   \n",
       "4    2  3215    2  7731    3  4156    4  2802    4  5628  ...       2   19   \n",
       "\n",
       "   religion  married  familysize  major_category  depression_score  \\\n",
       "0        12        1           2               0                41   \n",
       "1         7        1           4               0                38   \n",
       "2         4        1           3               0                53   \n",
       "3         4        1           5               6                30   \n",
       "4        10        1           4               8                46   \n",
       "\n",
       "   anxiety_score  stress_score  das_score  \n",
       "0             48            54         86  \n",
       "1             31            41         66  \n",
       "2             26            31         66  \n",
       "3             31            30         55  \n",
       "4             54            43         86  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset, validate_dataset, show_datasets  # Now you can import the package\n",
    "\n",
    "\n",
    "ds = load_dataset(\"./../data/categorized_v4_numeric.csv\")\n",
    "ds = validate_dataset(ds)\n",
    "\n",
    "ds.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf56eb",
   "metadata": {},
   "source": [
    "## Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a03090e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q4E</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q5E</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>religion</th>\n",
       "      <th>married</th>\n",
       "      <th>familysize</th>\n",
       "      <th>major_category</th>\n",
       "      <th>depression_score</th>\n",
       "      <th>anxiety_score</th>\n",
       "      <th>stress_score</th>\n",
       "      <th>das_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3890</td>\n",
       "      <td>4</td>\n",
       "      <td>2122</td>\n",
       "      <td>2</td>\n",
       "      <td>1944</td>\n",
       "      <td>4</td>\n",
       "      <td>2044</td>\n",
       "      <td>4</td>\n",
       "      <td>2153</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8118</td>\n",
       "      <td>1</td>\n",
       "      <td>2890</td>\n",
       "      <td>2</td>\n",
       "      <td>4777</td>\n",
       "      <td>3</td>\n",
       "      <td>3090</td>\n",
       "      <td>4</td>\n",
       "      <td>5078</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5784</td>\n",
       "      <td>1</td>\n",
       "      <td>4373</td>\n",
       "      <td>4</td>\n",
       "      <td>3242</td>\n",
       "      <td>1</td>\n",
       "      <td>6470</td>\n",
       "      <td>4</td>\n",
       "      <td>3927</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5081</td>\n",
       "      <td>3</td>\n",
       "      <td>6837</td>\n",
       "      <td>2</td>\n",
       "      <td>5521</td>\n",
       "      <td>1</td>\n",
       "      <td>4556</td>\n",
       "      <td>3</td>\n",
       "      <td>3269</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3215</td>\n",
       "      <td>2</td>\n",
       "      <td>7731</td>\n",
       "      <td>3</td>\n",
       "      <td>4156</td>\n",
       "      <td>4</td>\n",
       "      <td>2802</td>\n",
       "      <td>4</td>\n",
       "      <td>5628</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A   Q1E  Q2A   Q2E  Q3A   Q3E  Q4A   Q4E  Q5A   Q5E  ...  gender  age  \\\n",
       "0    4  3890    4  2122    2  1944    4  2044    4  2153  ...       2   16   \n",
       "1    4  8118    1  2890    2  4777    3  3090    4  5078  ...       2   16   \n",
       "2    3  5784    1  4373    4  3242    1  6470    4  3927  ...       2   17   \n",
       "3    2  5081    3  6837    2  5521    1  4556    3  3269  ...       2   13   \n",
       "4    2  3215    2  7731    3  4156    4  2802    4  5628  ...       2   19   \n",
       "\n",
       "   religion  married  familysize  major_category  depression_score  \\\n",
       "0        12        1           2               0                41   \n",
       "1         7        1           4               0                38   \n",
       "2         4        1           3               0                53   \n",
       "3         4        1           5               6                30   \n",
       "4        10        1           4               8                46   \n",
       "\n",
       "   anxiety_score  stress_score  das_score  \n",
       "0             48            54         86  \n",
       "1             31            41         66  \n",
       "2             26            31         66  \n",
       "3             31            30         55  \n",
       "4             54            43         86  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.drop(columns=[\"country\"])\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ca0c0",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bf3da1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for depression_score:\n",
      "Accuracy: 0.2578252671275927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          14       0.89      1.00      0.94       182\n",
      "          15       0.62      0.67      0.64       172\n",
      "          16       0.35      0.54      0.42       177\n",
      "          17       0.33      0.30      0.32       183\n",
      "          18       0.26      0.29      0.28       153\n",
      "          19       0.19      0.19      0.19       174\n",
      "          20       0.23      0.20      0.21       171\n",
      "          21       0.18      0.21      0.19       178\n",
      "          22       0.20      0.19      0.20       197\n",
      "          23       0.16      0.18      0.17       186\n",
      "          24       0.17      0.19      0.18       174\n",
      "          25       0.19      0.14      0.16       188\n",
      "          26       0.17      0.19      0.18       170\n",
      "          27       0.16      0.12      0.14       208\n",
      "          28       0.23      0.22      0.22       228\n",
      "          29       0.16      0.17      0.16       199\n",
      "          30       0.17      0.23      0.20       188\n",
      "          31       0.13      0.16      0.14       202\n",
      "          32       0.22      0.19      0.20       215\n",
      "          33       0.15      0.13      0.14       212\n",
      "          34       0.15      0.14      0.14       195\n",
      "          35       0.15      0.14      0.15       171\n",
      "          36       0.11      0.09      0.10       181\n",
      "          37       0.14      0.13      0.13       196\n",
      "          38       0.14      0.10      0.11       194\n",
      "          39       0.12      0.10      0.11       200\n",
      "          40       0.17      0.20      0.18       182\n",
      "          41       0.14      0.13      0.14       180\n",
      "          42       0.17      0.16      0.16       173\n",
      "          43       0.14      0.16      0.15       164\n",
      "          44       0.14      0.13      0.13       191\n",
      "          45       0.12      0.14      0.13       159\n",
      "          46       0.22      0.16      0.18       185\n",
      "          47       0.20      0.21      0.20       164\n",
      "          48       0.25      0.18      0.21       196\n",
      "          49       0.15      0.14      0.14       180\n",
      "          50       0.20      0.16      0.18       170\n",
      "          51       0.23      0.23      0.23       174\n",
      "          52       0.33      0.26      0.29       181\n",
      "          53       0.26      0.36      0.30       152\n",
      "          54       0.33      0.35      0.34       148\n",
      "          55       0.54      0.64      0.59       166\n",
      "          56       0.87      1.00      0.93       296\n",
      "\n",
      "    accuracy                           0.26      7955\n",
      "   macro avg       0.24      0.25      0.24      7955\n",
      "weighted avg       0.25      0.26      0.25      7955\n",
      "\n",
      "\n",
      "Results for anxiety_score:\n",
      "Accuracy: 0.2032683846637335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          14       0.82      1.00      0.90       182\n",
      "          15       0.55      0.62      0.58       192\n",
      "          16       0.36      0.42      0.39       221\n",
      "          17       0.30      0.37      0.33       253\n",
      "          18       0.26      0.28      0.27       266\n",
      "          19       0.19      0.18      0.18       248\n",
      "          20       0.26      0.26      0.26       313\n",
      "          21       0.20      0.21      0.20       277\n",
      "          22       0.18      0.20      0.19       260\n",
      "          23       0.17      0.17      0.17       265\n",
      "          24       0.15      0.19      0.16       270\n",
      "          25       0.13      0.13      0.13       279\n",
      "          26       0.16      0.15      0.15       291\n",
      "          27       0.15      0.20      0.17       258\n",
      "          28       0.16      0.16      0.16       266\n",
      "          29       0.14      0.15      0.14       238\n",
      "          30       0.13      0.12      0.13       272\n",
      "          31       0.13      0.09      0.10       272\n",
      "          32       0.15      0.12      0.13       243\n",
      "          33       0.13      0.12      0.12       216\n",
      "          34       0.12      0.10      0.11       242\n",
      "          35       0.17      0.18      0.17       205\n",
      "          36       0.12      0.24      0.16       203\n",
      "          37       0.13      0.09      0.10       207\n",
      "          38       0.12      0.11      0.11       213\n",
      "          39       0.11      0.11      0.11       189\n",
      "          40       0.13      0.08      0.10       178\n",
      "          41       0.11      0.08      0.09       170\n",
      "          42       0.06      0.07      0.06       131\n",
      "          43       0.07      0.05      0.06       149\n",
      "          44       0.16      0.14      0.15       130\n",
      "          45       0.10      0.07      0.08       130\n",
      "          46       0.22      0.27      0.24       110\n",
      "          47       0.11      0.10      0.10        94\n",
      "          48       0.16      0.11      0.13        96\n",
      "          49       0.09      0.06      0.07        80\n",
      "          50       0.26      0.26      0.26        72\n",
      "          51       0.27      0.15      0.19        67\n",
      "          52       0.23      0.14      0.17        50\n",
      "          53       0.28      0.42      0.34        43\n",
      "          54       0.56      0.21      0.31        43\n",
      "          55       0.43      0.19      0.27        31\n",
      "          56       0.54      0.97      0.70        40\n",
      "\n",
      "    accuracy                           0.20      7955\n",
      "   macro avg       0.22      0.22      0.21      7955\n",
      "weighted avg       0.20      0.20      0.20      7955\n",
      "\n",
      "\n",
      "Results for stress_score:\n",
      "Accuracy: 0.20188560653676932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          14       0.78      0.94      0.86        66\n",
      "          15       0.45      0.52      0.48        71\n",
      "          16       0.31      0.27      0.29        84\n",
      "          17       0.23      0.25      0.24       102\n",
      "          18       0.27      0.25      0.26       127\n",
      "          19       0.22      0.24      0.23       135\n",
      "          20       0.20      0.17      0.18       161\n",
      "          21       0.20      0.22      0.21       158\n",
      "          22       0.15      0.13      0.14       159\n",
      "          23       0.19      0.22      0.21       189\n",
      "          24       0.23      0.27      0.24       200\n",
      "          25       0.16      0.18      0.17       209\n",
      "          26       0.20      0.20      0.20       232\n",
      "          27       0.19      0.13      0.16       220\n",
      "          28       0.19      0.30      0.23       218\n",
      "          29       0.13      0.13      0.13       242\n",
      "          30       0.12      0.11      0.12       251\n",
      "          31       0.15      0.14      0.14       243\n",
      "          32       0.18      0.22      0.20       253\n",
      "          33       0.12      0.11      0.11       227\n",
      "          34       0.15      0.13      0.14       228\n",
      "          35       0.19      0.20      0.20       254\n",
      "          36       0.18      0.22      0.19       253\n",
      "          37       0.13      0.11      0.12       243\n",
      "          38       0.16      0.16      0.16       258\n",
      "          39       0.15      0.15      0.15       248\n",
      "          40       0.12      0.15      0.13       196\n",
      "          41       0.15      0.12      0.13       240\n",
      "          42       0.15      0.16      0.15       244\n",
      "          43       0.19      0.19      0.19       248\n",
      "          44       0.14      0.11      0.13       231\n",
      "          45       0.19      0.19      0.19       199\n",
      "          46       0.13      0.13      0.13       179\n",
      "          47       0.18      0.16      0.17       192\n",
      "          48       0.21      0.19      0.20       172\n",
      "          49       0.22      0.16      0.19       162\n",
      "          50       0.17      0.20      0.19       139\n",
      "          51       0.26      0.26      0.26       164\n",
      "          52       0.26      0.23      0.24       153\n",
      "          53       0.33      0.31      0.32       134\n",
      "          54       0.29      0.29      0.29        86\n",
      "          55       0.51      0.36      0.42        73\n",
      "          56       0.79      0.98      0.87       112\n",
      "\n",
      "    accuracy                           0.20      7955\n",
      "   macro avg       0.23      0.24      0.23      7955\n",
      "weighted avg       0.20      0.20      0.20      7955\n",
      "\n",
      "\n",
      "Results for das_score:\n",
      "Accuracy: 0.12369578881206789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          25       0.44      0.48      0.46        23\n",
      "          26       0.33      0.11      0.17        18\n",
      "          27       0.44      0.56      0.50        55\n",
      "          28       0.28      0.39      0.32        57\n",
      "          29       0.14      0.02      0.04        41\n",
      "          30       0.26      0.32      0.29        98\n",
      "          31       0.17      0.25      0.20        92\n",
      "          32       0.00      0.00      0.00        47\n",
      "          33       0.17      0.21      0.19       108\n",
      "          34       0.21      0.28      0.24       132\n",
      "          35       0.00      0.00      0.00        57\n",
      "          36       0.12      0.20      0.15       135\n",
      "          37       0.19      0.23      0.21       132\n",
      "          38       0.00      0.00      0.00        61\n",
      "          39       0.11      0.16      0.13       132\n",
      "          40       0.13      0.12      0.13       149\n",
      "          41       0.00      0.00      0.00        53\n",
      "          42       0.15      0.20      0.17       138\n",
      "          43       0.17      0.19      0.18       139\n",
      "          44       0.00      0.00      0.00        63\n",
      "          45       0.14      0.14      0.14       155\n",
      "          46       0.09      0.08      0.09       159\n",
      "          47       0.00      0.00      0.00        76\n",
      "          48       0.09      0.12      0.10       163\n",
      "          49       0.10      0.17      0.13       173\n",
      "          50       0.08      0.11      0.09       159\n",
      "          51       0.00      0.00      0.00        83\n",
      "          52       0.06      0.06      0.06       179\n",
      "          53       0.08      0.12      0.09       173\n",
      "          54       0.00      0.00      0.00        84\n",
      "          55       0.12      0.15      0.13       167\n",
      "          56       0.12      0.15      0.13       175\n",
      "          57       0.00      0.00      0.00        97\n",
      "          58       0.10      0.09      0.10       173\n",
      "          59       0.11      0.14      0.12       191\n",
      "          60       0.00      0.00      0.00        81\n",
      "          61       0.10      0.13      0.11       175\n",
      "          62       0.11      0.12      0.11       199\n",
      "          63       0.07      0.02      0.04        84\n",
      "          64       0.09      0.13      0.11       173\n",
      "          65       0.05      0.07      0.06       163\n",
      "          66       0.25      0.02      0.04        93\n",
      "          67       0.09      0.11      0.10       179\n",
      "          68       0.10      0.11      0.11       172\n",
      "          69       0.00      0.00      0.00        82\n",
      "          70       0.10      0.11      0.11       174\n",
      "          71       0.09      0.09      0.09       162\n",
      "          72       0.08      0.01      0.02        69\n",
      "          73       0.08      0.07      0.08       174\n",
      "          74       0.09      0.14      0.11       150\n",
      "          75       0.10      0.13      0.11       147\n",
      "          76       0.00      0.00      0.00        71\n",
      "          77       0.11      0.13      0.12       130\n",
      "          78       0.07      0.07      0.07       124\n",
      "          79       0.00      0.00      0.00        65\n",
      "          80       0.14      0.16      0.15       140\n",
      "          81       0.17      0.14      0.15       115\n",
      "          82       0.00      0.00      0.00        47\n",
      "          83       0.11      0.16      0.13       110\n",
      "          84       0.14      0.15      0.14       109\n",
      "          85       0.00      0.00      0.00        47\n",
      "          86       0.13      0.16      0.15       104\n",
      "          87       0.12      0.09      0.10        85\n",
      "          88       0.00      0.00      0.00        47\n",
      "          89       0.08      0.09      0.08        79\n",
      "          90       0.10      0.07      0.08        90\n",
      "          91       1.00      0.02      0.05        43\n",
      "          92       0.11      0.15      0.13        53\n",
      "          93       0.20      0.15      0.17        61\n",
      "          94       0.00      0.00      0.00        27\n",
      "          95       0.20      0.19      0.19        48\n",
      "          96       0.15      0.16      0.15        43\n",
      "          97       0.00      0.00      0.00        13\n",
      "          98       0.27      0.27      0.27        33\n",
      "          99       0.17      0.20      0.19        20\n",
      "         100       0.58      0.89      0.70        37\n",
      "\n",
      "    accuracy                           0.12      7955\n",
      "   macro avg       0.13      0.13      0.12      7955\n",
      "weighted avg       0.11      0.12      0.11      7955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define features (X) and multiple targets (y)\n",
    "X = ds.drop(\n",
    "    columns=[\n",
    "        \"depression_score\",\n",
    "        \"anxiety_score\",\n",
    "        \"stress_score\",\n",
    "        \"das_score\",\n",
    "        \"country\",\n",
    "    ]\n",
    ")\n",
    "y = ds[\n",
    "    [\"depression_score\", \"anxiety_score\", \"stress_score\", \"das_score\"]\n",
    "]  # All target columns\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize the MultiOutputClassifier with RandomForestClassifier\n",
    "# You can adjust n_estimators and other parameters as needed\n",
    "multi_target_model = MultiOutputClassifier(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42)\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "multi_target_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = multi_target_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model - need to evaluate each target separately\n",
    "target_names = [\"depression_score\", \"anxiety_score\", \"stress_score\", \"das_score\"]\n",
    "\n",
    "for i, target in enumerate(target_names):\n",
    "    print(f\"\\nResults for {target}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test.iloc[:, i], y_pred[:, i])}\")\n",
    "    print(classification_report(y_test.iloc[:, i], y_pred[:, i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64091cf",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b607d80b",
   "metadata": {},
   "source": [
    "```python\n",
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(multi_target_model, 'multi_target_model.pkl')\n",
    "\n",
    "print(\"Model saved as 'multi_target_model.pkl'\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
